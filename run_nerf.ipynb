{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a8307b3-99b4-43c0-9d3d-975bd63c8bc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import read_write_model as colmap_reader\n",
    "import numpy as np\n",
    "import torch\n",
    "import imageio.v3 as iio\n",
    "import matplotlib.pyplot as plt\n",
    "from datautils import read_data\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ccc697e-2bd5-4c18-90a8-7812d82507db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Poses...\n",
      "Done\n",
      "Reading Images...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "imagedir = './images'\n",
    "camFile = 'cameras.bin'\n",
    "imgFile = 'images.bin'\n",
    "\n",
    "images, c2w, H, W, F = read_data(camFile, imgFile, imagedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b1ca4baf-0844-46ec-a6fe-dd16cb3f0790",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (2304,3072,1,3) (128,3,3) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m i, j \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmeshgrid(torch\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m, W, dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mint32), torch\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m, H, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mint32), indexing \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m dirs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([(i \u001b[38;5;241m-\u001b[39m W \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.5\u001b[39m) \u001b[38;5;241m/\u001b[39m F, \u001b[38;5;241m-\u001b[39m(j \u001b[38;5;241m-\u001b[39m H \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m.5\u001b[39m)\u001b[38;5;241m/\u001b[39mF, \u001b[38;5;241m-\u001b[39mtorch\u001b[38;5;241m.\u001b[39mones_like(i)], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m rays_d \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(\u001b[43mdirs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnewaxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mc2w\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      4\u001b[0m rays_o \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbroadcast_to(torch\u001b[38;5;241m.\u001b[39mTensor(c2w[:, :\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]), rays_d\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (2304,3072,1,3) (128,3,3) "
     ]
    }
   ],
   "source": [
    "i, j = torch.meshgrid(torch.arange(0, W, dtype = torch.int32), torch.arange(0, H, dtype=torch.int32), indexing = 'xy')\n",
    "dirs = torch.stack([(i - W * 0.5) / F, -(j - H * .5)/F, -torch.ones_like(i)], -1)\n",
    "rays_d = torch.sum(dirs[..., np.newaxis, :] * c2w[:, :3, :3], -1)\n",
    "rays_o = torch.broadcast_to(torch.Tensor(c2w[:, :3, -1]), rays_d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f692f0d-8e4e-48be-9dca-640fa88b2ef1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rays_o = torch.flatten(rays_o, start_dim = 0, end_dim = 1)\n",
    "rays_d = torch.flatten(rays_d, start_dim = 0, end_dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf304266-3785-4edc-9fab-afee63e9373a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "aa01c19c-3bed-478f-ba58-39f7c34f2523",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7077888, 60])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = PositionalEncoding()\n",
    "posenc, direnc = enc.forward(rays_o, rays_d)\n",
    "posenc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "04ecbd27-ed1c-446e-9a89-4b0cfb8c6b5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding():\n",
    "    def __init__(self, L_pos = 10, L_dir = 4):\n",
    "        '''\n",
    "        L_pos: Position (xyz) coordinates will be mapped to L_pos * 2 dimentions\n",
    "        L_dir: Viewing direction unit vector will be mapped to L_dir * 2 dimentions\n",
    "        '''\n",
    "        self.L_pos = 10\n",
    "        self.L_dir = 4\n",
    "\n",
    "    def forward(self, pos, vdir):\n",
    "        posenc = [] #Try including base pos and dir\n",
    "        direnc = []\n",
    "        \n",
    "        for i in range(0, self.L_pos):\n",
    "            for f in [torch.sin, torch.cos]:\n",
    "                posenc.append(f(pos * np.pi * (2 ** i)))\n",
    "                              \n",
    "        for j in range(0, self.L_dir):\n",
    "            for f in [torch.sin, torch.cos]:\n",
    "                direnc.append(f(vdir * np.pi * (2 ** i)))\n",
    "        \n",
    "        posenc = torch.cat(posenc, -1)\n",
    "        direnc = torch.cat(direnc, -1)\n",
    "        \n",
    "        return posenc, direnc\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebc7a7e-89e9-449a-9786-7d51e2869f31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
